{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Rrx87HuBrwlzw9s6-pM_MxlEmb9Lva3m",
      "authorship_tag": "ABX9TyP62lt6c8tf8yshzPgEztut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miuuu13/LONG_READ_pipeline/blob/main/LONG_READ_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxtikEQYlE-L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project: LONG READ\n",
        "\n",
        "start: 08.02.2024\n",
        "\n",
        "Steps to take:\n",
        "\n",
        "* generate long read data\n",
        "* split the single long read to fragments that can be put into a NN\n",
        "* Basecalling on fragments\n",
        "* Realign sequence fragments\n",
        "* Keep overlap? to ensure that correct fragments are combined in the correct order\n",
        "\n",
        "* Use Nextflow?\n",
        "\n",
        "* Make a repo on my machine or should I try it in Colab?\n",
        "\n"
      ],
      "metadata": {
        "id": "3xUnCyU7lNHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import os"
      ],
      "metadata": {
        "id": "QrAzGuNaKMbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# script to generate long reads\n",
        "# /content/drive/MyDrive/template_median68pA_200mv.txt\n",
        "\n",
        "kmer_info = pd.read_csv('template_median68pA_200mv.txt', delim_whitespace=True)\n",
        "kmer_info = kmer_info.values\n",
        "seq_len = 35\n",
        "time_points = 6000 #long read\n",
        "\n",
        "path_in = os.getcwd()\n",
        "#/content/drive/MyDrive/LONG_READ_training_data\n",
        "path_save = path_in + \"\\LONG_READ_training_data\"\n",
        "#\"/Simulated_data_30JAN24/Simulated_data_n0_w1200_b64\"\n",
        "\n",
        "N_batch = 3 #try to generate three files first, just to check\n",
        "batch_size = 32\n",
        "\n",
        "def Generate_sim_signal(N_batch, batch_size , path, kmer_info, seq_len , time_points):\n",
        "\n",
        "    seq_len = seq_len + 5\n",
        "    labels = 5\n",
        "    kmer_length = 5\n",
        "\n",
        "    for j in range (N_batch):\n",
        "\n",
        "        print(j)\n",
        "\n",
        "        Sim_raw_signal_tot = np.zeros([batch_size,time_points])\n",
        "        Map_raw_signal_tot = np.zeros([batch_size,time_points,labels])\n",
        "        #ramp_signal_tot = np.zeros([batch_size,time_points,1])\n",
        "\n",
        "        for k in range(batch_size):\n",
        "\n",
        "            #% this part is used for generate random time step where the k-mer is readed\n",
        "            Rand_seq = np.random.randint(0,4, seq_len)\n",
        "            rand_seq_base =np.empty(seq_len, dtype=str)\n",
        "            Sim_raw_signal = np.zeros([time_points])\n",
        "            Map_raw_signal_S = np.zeros([time_points,labels])\n",
        "\n",
        "            # dictionary version one\n",
        "            base_dict = { 0:\"A\", 1:\"C\", 2:\"G\", 3:\"T\"} # use base_dict\n",
        "            #base_dict_2 = { \"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
        "\n",
        "            for i in range(len(Rand_seq)):\n",
        "\n",
        "                rand_seq_base[i] = base_dict[Rand_seq[i]]\n",
        "\n",
        "            probe_raw_data = 0;\n",
        "            mu, sigma = 3.686, 0.4254\n",
        "\n",
        "            for i in range(seq_len - kmer_length + 1):\n",
        "\n",
        "                #obtain the k-mer Raw-signal value\n",
        "\n",
        "                if i > 0:\n",
        "\n",
        "                    #find the k-mer value in the table and associate the specific signal value\n",
        "\n",
        "                    Single_kmer_vector = rand_seq_base[i: i + kmer_length]\n",
        "\n",
        "                    Single_kmer = ''.join(rand_seq_base[i: i + kmer_length])\n",
        "                    probe_kmer = np.where(kmer_info[:,0] == Single_kmer)[0]\n",
        "\n",
        "                    # k-mer signal depends on a gaussian distrbution center on a specific value.\n",
        "                    # here we generate the k-mer distribution and create the k-mer signal from it.\n",
        "\n",
        "                    kmer_center = kmer_info[probe_kmer[0],1]\n",
        "                    kmer_std = (1/4)*kmer_info[probe_kmer[0],2]\n",
        "                    Signal_kmer = np.random.normal(kmer_center, kmer_std)\n",
        "\n",
        "                    # from the distribution, obtain the number of time points that the k-mer is present\n",
        "                    # in the signal\n",
        "\n",
        "                    N_step = int(np.random.lognormal(mu, sigma))\n",
        "\n",
        "                    while N_step < 20:\n",
        "                        N_step = int(np.random.lognormal(mu, sigma))\n",
        "\n",
        "                    Sim_raw_signal[probe_raw_data : probe_raw_data + N_step] = Signal_kmer\n",
        "\n",
        "                    Spc = 3\n",
        "\n",
        "                    if i == 1:\n",
        "\n",
        "                        if np.random.randint(2) == 0:\n",
        "\n",
        "                            Map_raw_signal_S[probe_raw_data : probe_raw_data + N_step - Spc, base_dict_2[Single_kmer_vector[-1]]] = 1\n",
        "                            Map_raw_signal_S[probe_raw_data + N_step - Spc : probe_raw_data + N_step, -1] = 1\n",
        "\n",
        "                        else:\n",
        "                            Map_raw_signal_S[probe_raw_data + Spc : probe_raw_data + N_step -Spc, base_dict_2[Single_kmer_vector[-1]]] = 1\n",
        "\n",
        "                            #this is for adding blank signal\n",
        "                            Map_raw_signal_S[0 : Spc, -1] = 1\n",
        "                            Map_raw_signal_S[probe_raw_data + N_step -Spc : probe_raw_data + N_step, -1] = 1\n",
        "\n",
        "                    else:\n",
        "\n",
        "                        Map_raw_signal_S[probe_raw_data + Spc : probe_raw_data + N_step -Spc, base_dict_2[Single_kmer_vector[-1]]] = 1\n",
        "\n",
        "                        #this is for adding blank signal\n",
        "                        Map_raw_signal_S[probe_raw_data : probe_raw_data + Spc, -1] = 1\n",
        "                        Map_raw_signal_S[probe_raw_data + N_step -Spc : probe_raw_data + N_step, -1] = 1\n",
        "\n",
        "                    probe_raw_data += N_step\n",
        "\n",
        "            # filter the frequency\n",
        "\n",
        "            filtered_signal = signal.savgol_filter(Sim_raw_signal, 11, 1) #was 10, 1 must be odd\n",
        "\n",
        "            # add noise #remove this for Project WINDOW\n",
        "            noise_level = 0 # (np.random.randint(3) + 1)/200 # 0 for 0%, 0.02 for 2% noise, 0.04 for 4% noise\n",
        "            Sim_signal_final = filtered_signal + np.max(filtered_signal)*np.random.normal(0,noise_level, len(filtered_signal))\n",
        "\n",
        "            #code for the median. for dorado they use median\n",
        "            median = np.median(Sim_signal_final)\n",
        "            std_med = np.median(np.abs(Sim_signal_final-median))*1.4826 + np.finfo(np.float32).eps\n",
        "            Sim_signal_final = (Sim_signal_final - median)/std_med\n",
        "\n",
        "            Sim_raw_signal_tot[k] = Sim_signal_final #filtered_signal\n",
        "            Map_raw_signal_tot[k] = Map_raw_signal_S\n",
        "\n",
        "        file_name = \"train_data_{}.npz\".format(j);\n",
        "\n",
        "        np.savez_compressed(os.path.join(path,file_name), signal_train = Sim_raw_signal_tot, map_onehot = Map_raw_signal_tot)\n",
        "\n",
        "Generate_sim_signal(N_batch, batch_size , path_save, kmer_info, seq_len, time_points)\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = os.getcwd()\n",
        "dirs = path + \"/test\"\n",
        "\n",
        "batch_size = 64;\n",
        "files_list = os.listdir(dirs)\n",
        "\n",
        "y_true = np.zeros([batch_size,1200,6])\n",
        "x_true = np.zeros([batch_size,1200])\n",
        "\n",
        "for i in range (1):\n",
        "\n",
        "    with np.load(dirs + \"/\" + files_list[0]) as data:\n",
        "\n",
        "        seq = data[\"map_onehot\"]\n",
        "        y_true = seq\n",
        "\n",
        "        x_true = data[\"signal_train\"]"
      ],
      "metadata": {
        "id": "Z8WogTDkHs27"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}